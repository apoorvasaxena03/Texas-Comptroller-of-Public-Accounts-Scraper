{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas Comptroller of Public Accounts - Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "# Import date class from datetime module\n",
    "from datetime import date\n",
    "\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path  # Import Path to handle file paths easily\n",
    "\n",
    "# Importing Logger\n",
    "from custom_logger import CustomLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[scraper_ipynb] INFO (10-11 08:52 PM): ################## Logging Started ################## (Line: 11) [772446353.py]\n"
     ]
    }
   ],
   "source": [
    "# Define log directory and ensure it exists\n",
    "log_dir = r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\Python\\Scraping\\Texas-Comptroller-of-Public-Accounts-Scraper\\logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create a CustomLogger instance\n",
    "logger = CustomLogger(log_file_name=\"scraper_log\",\n",
    "                      log_dir_path=log_dir, logger_name='scraper_ipynb'\n",
    "                      ).get_logger()\n",
    "\n",
    "# Start the logger\n",
    "logger.info(f\"################## Logging Started ##################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Scraper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _LeaseDropNaturalGas_WebScraper:\n",
    "\n",
    "    def __init__(self, csv_dir: str = \"./\", scraped_csv: str = \"scraped_leases.csv\") -> None:\n",
    "        \"\"\"\n",
    "        Initialize the web scraper.\n",
    "\n",
    "        Args:\n",
    "            scraped_csv (str): The CSV file name or path to store scraped data. Defaults to \"scraped_leases.csv\".\n",
    "        \n",
    "        Example:\n",
    "            scraper = _LeaseDropNaturalGas_WebScraper(csv_dir=\"/path/to/directory\")\n",
    "        \"\"\"\n",
    "        self.site_key: str = '6Lf6Z5sUAAAAACg7ECAeRMcnAo2_WfoKUeNYXkj_'\n",
    "        self.login_url: str = 'https://mycpa.cpa.state.tx.us/cong/loginForward.do?phase=check'\n",
    "        self.ngl_drop_url: str = 'https://mycpa.cpa.state.tx.us/cong/leaseDropNGAction.do'\n",
    "        self.xpath_leaseNo: str = '//*[@id=\"leaseNum\"]'\n",
    "        self.xpath_begDt: str = '//*[@id=\"begFilPrd\"]'\n",
    "        self.xpath_endDt: str = '//*[@id=\"endFilPrd\"]'\n",
    "        self.xpath_submitForm: str = '//*[@id=\"leaseDropNGForm\"]/span[7]/p/input'\n",
    "        self.xpath_lease_table: str = '//*[@id=\"menucontenttable\"]/table/tbody/tr/td[2]/div/table'\n",
    "        self.xpath_time_period_error: str = '//*[@id=\"leaseDropNGForm\"]/span[2]/ul/li/strong'\n",
    "        self.driver: WebDriver  = None\n",
    "        self._initialize_driver()\n",
    "\n",
    "        # Handle the file path: set the absolute path for the CSV file\n",
    "        self.scraped_csv: str = os.path.join(os.path.abspath(csv_dir), scraped_csv)\n",
    "\n",
    "\n",
    "    def _initialize_driver(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the Chrome WebDriver.\n",
    "        \"\"\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # options.add_argument('--headless')  # Optional: run in headless mode\n",
    "        options.add_argument('--disable-gpu')  # Optional: disable GPU\n",
    "        options.add_argument('--no-sandbox')  # Optional: required for some environments\n",
    "\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "    def _load_page(self) -> None:\n",
    "        \"\"\"\n",
    "        Load the login and Natural Gas Inquiry drop page.\n",
    "        \"\"\"\n",
    "        if self.driver is None:\n",
    "            raise RuntimeError(\"WebDriver is not initialized.\")\n",
    "        \n",
    "        self.driver.maximize_window()\n",
    "        self.driver.get(self.login_url)\n",
    "        time.sleep(0.5)\n",
    "        self.driver.get(self.ngl_drop_url)\n",
    "        wait = WebDriverWait(self.driver, 3)\n",
    "        wait.until(lambda d: d.execute_script(\"return typeof grecaptcha !== 'undefined'\"))\n",
    "\n",
    "\n",
    "    def _get_recaptcha_token(self) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve the reCAPTCHA token from the webpage.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The reCAPTCHA token as a string, or None if the token retrieval fails.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.driver is None:\n",
    "            raise RuntimeError(\"WebDriver is not initialized.\")\n",
    "\n",
    "        self._load_page()\n",
    "        \n",
    "        token = self.driver.execute_script(f'''\n",
    "            return grecaptcha.execute('{self.site_key}', {{action: 'homepage'}}).then(function(token) {{\n",
    "                return token;\n",
    "            }});\n",
    "        ''')\n",
    "        \n",
    "        return token\n",
    "\n",
    "\n",
    "    def _get_NGL_Inquiry_html(self, lease_no: str, beg_dt: str, end_dt: str) -> str:\n",
    "        \"\"\"\n",
    "        Scrape the Natural Gas Inquiry form based on lease_no, beg_dt, and end_dt.\n",
    "        \n",
    "        Args:\n",
    "            lease_no (str): The lease number to search (6 or all digits).\n",
    "            beg_dt (str): Begining period (yymm or yy)\n",
    "            end_dt (str): Ending period (yymm or yy)\n",
    "        \n",
    "        Returns:\n",
    "            Optional[str]: The HTML content of the page or None if an error occurred.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.driver is None:\n",
    "            raise RuntimeError(\"WebDriver is not initialized.\")\n",
    "        \n",
    "        # Format Lease Number\n",
    "        try:\n",
    "            if len(lease_no) == 11:\n",
    "                formatted_lease_no = lease_no.split('-')[1]\n",
    "            \n",
    "            elif len(lease_no) == 6:\n",
    "                formatted_lease_no = lease_no\n",
    "\n",
    "        except ValueError:\n",
    "            logger.error(f'Lease number {lease_no} entered not of 6 or 11 digits')\n",
    "        \n",
    "        # Filling Lease Number\n",
    "        self.driver.find_element(By.XPATH, self.xpath_leaseNo).send_keys(formatted_lease_no)\n",
    "\n",
    "        # Filling Begining Period\n",
    "        self.driver.find_element(By.XPATH, self.xpath_begDt).send_keys(beg_dt)\n",
    "\n",
    "        # Filling Ending Period\n",
    "        self.driver.find_element(By.XPATH, self.xpath_endDt).send_keys(end_dt)\n",
    "\n",
    "        # Running the Inquiry Form\n",
    "        time.sleep(1)\n",
    "        self.driver.find_element(By.XPATH, self.xpath_submitForm).click()\n",
    "\n",
    "        # Visibility of the table header element\n",
    "        try:\n",
    "            # Wait until the table is located or timeout occurs\n",
    "            lease_table = WebDriverWait(self.driver, 2).until(\n",
    "                EC.presence_of_all_elements_located(\n",
    "                    (By.XPATH, self.xpath_lease_table)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if lease_table:\n",
    "                return self.driver.page_source\n",
    "        \n",
    "        except TimeoutException:\n",
    "            # Try running the form again\n",
    "                time.sleep(2)\n",
    "                self.driver.find_element(By.XPATH, self.xpath_submitForm).click()\n",
    "\n",
    "        except TimeoutException:\n",
    "            # If the lease table is not found, check for validation error\n",
    "            try:\n",
    "                validation_error = WebDriverWait(self.driver, 2).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, self.xpath_time_period_error))\n",
    "                )\n",
    "                # If validation error is found, log it\n",
    "                if validation_error:\n",
    "                    logger.error(f\"There was an error for lease: {lease_no} with start date: {beg_dt} and end date: {end_dt}\")\n",
    "                    return False\n",
    "            except TimeoutException:\n",
    "                # If neither lease table nor validation error is found, log accordingly\n",
    "                logger.debug(f\"Lease table not found or there was an error for lease: {lease_no} with start date: {beg_dt} and end date: {end_dt}.\")\n",
    "                return False\n",
    "\n",
    "        except NoSuchElementException as e:\n",
    "            # Optional: Log additional element-specific issues\n",
    "            logger.error(f\"An unexpected NoSuchElementException occurred for lease {lease_no}: {e}\")\n",
    "            return False\n",
    "    \n",
    "\n",
    "    def _clear_entry_labels(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear the input fields for Lease Number, Beginning Period, and Ending Period.\n",
    "\n",
    "        Returns:\n",
    "            None: This function does not return anything.\n",
    "        \"\"\"\n",
    "        # Clearing Lease Number\n",
    "        self.driver.find_element(By.XPATH, self.xpath_leaseNo).clear()\n",
    "\n",
    "        # Clearing Begining Period\n",
    "        self.driver.find_element(By.XPATH, self.xpath_begDt).clear()\n",
    "\n",
    "        # Clearing Ending Period\n",
    "        self.driver.find_element(By.XPATH, self.xpath_endDt).clear()\n",
    "\n",
    "\n",
    "    def _parse_html(self, html: str, raw: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parsing HTML content using Beautiful Soup into a DataFrame\n",
    "        \n",
    "        Args:\n",
    "            html (str): The HTML content as string.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The parsed and cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "        df_raw = pd.read_html(StringIO(str(soup.find_all('table'))))\n",
    "\n",
    "        df_LeaseNGL_raw = df_raw[1]\n",
    "\n",
    "        # Step 1: Identify rows where 'Primary Taxpayer #' contains 'Period' and extract the date part\n",
    "        df_LeaseNGL_raw['prod_dt'] = np.where(\n",
    "            df_LeaseNGL_raw['Primary Taxpayer #'].str.contains('Period', na=False),\n",
    "            df_LeaseNGL_raw['Primary Taxpayer #'].str.extract(r'Period: (\\d{4})', expand=False),\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        # Step 2: Forward fill the 'prod_dt' column to propagate the last valid date value\n",
    "        df_LeaseNGL_raw['prod_dt'] = df_LeaseNGL_raw['prod_dt'].ffill()\n",
    "\n",
    "\n",
    "        # Step 3: Convert 'prod_dt' from 'YYMM' to datetime format 'YYYY-MM-DD'\n",
    "        df_LeaseNGL_raw['prod_dt'] = pd.to_datetime(df_LeaseNGL_raw['prod_dt'], format='%y%m')\n",
    "\n",
    "        df_LeaseNGL_raw.insert(0, 'prod_dt', df_LeaseNGL_raw.pop('prod_dt')) # Insert 'prod_dt' as the first column\n",
    "\n",
    "        # Step 4: Filter out rows where column 'Primary Taxpayer #' contains 'Period'\n",
    "        df_LeaseNGL_cleaned = df_LeaseNGL_raw[~df_LeaseNGL_raw['Primary Taxpayer #'].str.contains('Period', na=False)].reset_index(drop=True)\n",
    "\n",
    "        # Step 5: Clean column names\n",
    "        df_LeaseNGL_cleaned.columns = df_LeaseNGL_cleaned.columns.str.lower()  # Convert to lowercase\n",
    "        df_LeaseNGL_cleaned.columns = df_LeaseNGL_cleaned.columns.str.replace('#', '')  # Remove '#' character\n",
    "        df_LeaseNGL_cleaned.columns = df_LeaseNGL_cleaned.columns.str.replace(' ', '_')  # Replace spaces with underscores\n",
    "\n",
    "        if raw:\n",
    "            return df_raw, df_LeaseNGL_cleaned\n",
    "        else:\n",
    "            return df_LeaseNGL_cleaned\n",
    "\n",
    "\n",
    "    def _read_scraped_csv(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Read the CSV file containing previously scraped leases.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame containing already scraped lease information.\n",
    "        \"\"\"\n",
    "        cols = ['lease_number', 'prod_dt', 'sub_type', 'primary_taxpayer_', 'comm_code', 'lse_typ',\n",
    "                'cnty/_dpi', 'exmt_typ', 'api_nbr', 'off_lease', 'other_party_taxpayer',\n",
    "                'secondary_tp_name', 'tax_reimb', 'ttl_lease_volume', 'your_volume',\n",
    "                'your_value', 'tax_due', 'gr_volume', 'gr_value', 'marketing_cost',\n",
    "                'net_tax_value', 'tax_rate', '05_tax_due', 'error_status'\n",
    "                ]\n",
    "        \n",
    "\n",
    "        if os.path.exists(self.scraped_csv):\n",
    "            return pd.read_csv(self.scraped_csv)\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    \n",
    "\n",
    "    def _append_to_csv(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Append the newly scraped lease data to the CSV file.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame with new lease data.\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.scraped_csv):\n",
    "            df.to_csv(self.scraped_csv, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv(self.scraped_csv, index=False)\n",
    "\n",
    "\n",
    "    def _quit(self) -> None:\n",
    "        \"\"\"\n",
    "        Close and quit the WebDriver.\n",
    "        \"\"\"\n",
    "        if self.driver is not None:\n",
    "            self.driver.close()\n",
    "            self.driver.quit()\n",
    "            self.driver = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle scraping outside of the class\n",
    "def scrape_leases(csv_dir: str, leases_df: pd.DataFrame, limit: int = 1000) -> None:\n",
    "    \"\"\"\n",
    "    Scrape leases from a DataFrame and stop after scraping 1,000 rows. Pause after every 20 rows.\n",
    "    If the page shows 'Cookies are required for this application', reload the page and resume scraping.\n",
    "    \n",
    "    Args:\n",
    "        csv_dir (str): The directory path where the scraped CSV file will be saved.\n",
    "        leases_df (pd.DataFrame): The DataFrame containing lease_number columns.\n",
    "        limit (int): The maximum number of leases to scrape in one session. Defaults to 1,000.\n",
    "    \"\"\"\n",
    "    # Initialize the scraper with the provided CSV directory\n",
    "    scraper = _LeaseDropNaturalGas_WebScraper(csv_dir=csv_dir)\n",
    "    scraped_df = scraper._read_scraped_csv()\n",
    "\n",
    "    # Filter out leases that have already been scraped\n",
    "    leases_to_scrape = leases_df[~(leases_df['lease_number'].isin(scraped_df['lease_number'].unique()))]\n",
    "\n",
    "    scraped_data: List[pd.DataFrame] = []\n",
    "    lease_not_found: List = []\n",
    "\n",
    "    try:\n",
    "        scraper._load_page()\n",
    "        \n",
    "        for count, lease_no in enumerate(leases_to_scrape['lease_number'], start=1):\n",
    "            retry_count = 0\n",
    "            max_retries = 3  # Set the maximum number of retries\n",
    "\n",
    "            while retry_count < max_retries:\n",
    "                # Check if the page requires cookies before scraping the lease number\n",
    "                soup = BeautifulSoup(scraper.driver.page_source, 'html.parser')\n",
    "                h1_text = soup.find('h1').get_text(strip=True)\n",
    "                \n",
    "                if h1_text == 'Cookies are required for this application.':\n",
    "                    logger.info(f\"Cookies required error. Reloading page for lease {lease_no}. Retry {retry_count + 1}/{max_retries}.\")\n",
    "                    scraper._load_page()  # Reload the page\n",
    "                    retry_count += 1  # Increment the retry count\n",
    "                    continue  # Retry the same lease_no after reloading the page\n",
    "                \n",
    "                # If the page does not require cookies, scrape the lease number\n",
    "                html_content: Optional[str] = scraper._get_NGL_Inquiry_html(lease_no, beg_dt='2201', end_dt='2410')\n",
    "\n",
    "                if html_content:\n",
    "                    df: pd.DataFrame = scraper._parse_html(html_content)\n",
    "                    df.insert(0, 'lease_number', lease_no)  # Create a new column with the lease_number and insert it at the beginning\n",
    "                    scraped_data.append(df)\n",
    "                    break  # Exit the retry loop if the scraping is successful\n",
    "                else:\n",
    "                    lease_not_found.append(lease_no)\n",
    "                    break  # Exit the retry loop if the lease is not found\n",
    "\n",
    "            scraper._clear_entry_labels()\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            if count % 20 == 0:\n",
    "                logger.info(f\"Pausing for 30 seconds after scraping {count} leases.\")\n",
    "                time.sleep(30)\n",
    "\n",
    "            if count >= limit:\n",
    "                break\n",
    "    finally:\n",
    "        scraper._quit()\n",
    "\n",
    "    # Save scraped data to CSV\n",
    "    if scraped_data:\n",
    "        full_df = pd.concat(scraped_data, ignore_index=True)\n",
    "        scraper._append_to_csv(full_df)\n",
    "        logger.info(f\"Scraped {count} leases and saved to {scraper.scraped_csv}.\")\n",
    "\n",
    "    if lease_not_found:\n",
    "        pd.DataFrame(lease_not_found, columns=['lease_number_NotFound']).to_csv(\n",
    "            r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\Python\\Scraping\\Texas-Comptroller-of-Public-Accounts-Scraper\\leases_not_found.csv\",\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Well Header Data from CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_WellHeader_CC():\n",
    "    \n",
    "    # Reading well header csv to pandas DataFrame\n",
    "    df_wellheader_raw = pd.read_csv('well_header.csv',low_memory=False)\n",
    "\n",
    "    # Cleaning up the column names\n",
    "    df_wellheader_modified = df_wellheader_raw.copy() # Copying the DataFrame\n",
    "    df_wellheader_modified.columns = df_wellheader_modified.columns.str.lower().str.replace(' ', '_')  # Convert to lowercase and replace spaces with underscores\n",
    "\n",
    "    # Only grab Lease Nos. that are complete\n",
    "    df_wellHeader_complete_LeaseNo = df_wellheader_modified[df_wellheader_modified['lease_number'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0) == 11].reset_index(drop=True)\n",
    "\n",
    "    # Returning unique LeaseNo. from well header\n",
    "    return pd.DataFrame(df_wellHeader_complete_LeaseNo['lease_number'].unique(), columns=['lease_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[scraper_ipynb] INFO (10-11 09:00 PM): Pausing for 30 seconds after scraping 20 leases. (Line: 57) [3337349766.py]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 121\u001b[0m, in \u001b[0;36m_LeaseDropNaturalGas_WebScraper._get_NGL_Inquiry_html\u001b[1;34m(self, lease_no, beg_dt, end_dt)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# Wait until the table is located or timeout occurs\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     lease_table \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpath_lease_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lease_table:\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mscrape_leases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mApoorva.Saxena\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive - Sitio Royalties\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProject - Apoorva\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPython\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mScraping\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTexas-Comptroller-of-Public-Accounts-Scraper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mleases_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mformatting_WellHeader_CC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mscrape_leases\u001b[1;34m(csv_dir, leases_df, limit)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Retry the same lease_no after reloading the page\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# If the page does not require cookies, scrape the lease number\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m html_content: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_NGL_Inquiry_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlease_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeg_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2201\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2410\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m html_content:\n\u001b[0;32m     44\u001b[0m     df: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39m_parse_html(html_content)\n",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m, in \u001b[0;36m_LeaseDropNaturalGas_WebScraper._get_NGL_Inquiry_html\u001b[1;34m(self, lease_no, beg_dt, end_dt)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# Try running the form again\u001b[39;00m\n\u001b[0;32m    132\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpath_submitForm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# If the lease table is not found, check for validation error\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Apoorva.Saxena\\AppData\\Local\\miniconda3\\envs\\venv_test\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrape_leases(csv_dir=r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\Python\\Scraping\\Texas-Comptroller-of-Public-Accounts-Scraper\", \n",
    "              leases_df = formatting_WellHeader_CC(), limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting_WellHeader_CC().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the scraper\n",
    "\n",
    "# scraper = _LeaseDropNaturalGas_WebScraper(\n",
    "#     csv_dir=r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\Python\\Scraping\\Texas-Comptroller-of-Public-Accounts-Scraper\"\n",
    "#     )\n",
    "\n",
    "# try:\n",
    "#     # Fill the form and get the HTML content\n",
    "#     html_content = scraper._get_NGL_Inquiry_html(lease_no='7C-017147-O', beg_dt='2301', end_dt='2410')\n",
    "\n",
    "#     # Parse the HTML and get the cleaned DataFrame\n",
    "#     if html_content:\n",
    "#         df = scraper._parse_html(html=html_content)\n",
    "# finally:\n",
    "#     scraper._quit()\n",
    "\n",
    "# str(date.today().year)[2:] + str(date.today().month).zfill(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
